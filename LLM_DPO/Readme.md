
## LLM DPO (Direct Preference Optimization)

ref: https://github.com/huggingface/trl</br>





### Temperature 


**Prediction of the Next Token Probability in Language Models**

- **Temperature** makes the probability of each next token in Softmax Regression more or less uniform during sampling.</br>

1. When the **temperature** value is low → the prediction probability of the token with the highest probability increases. → The most likely token is more likely to be sampled.</br>
2. When the **temperature** value is high → the probability of all tokens becomes uniform. → The probability of generating more diverse text increases.</br>

![image](https://github.com/user-attachments/assets/0825dc2b-572c-43a6-b58b-34873a321b66)



Ref: Here they provided some great examples to understand temperature meaning</br> 
https://lukesalamone.github.io/posts/what-is-temperature/</br>
https://platform.openai.com/playground/chat?mode=chat&models=gpt-4o-mini-2024-07-18</br>



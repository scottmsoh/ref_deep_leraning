
* Tokenization</br>

1) word tokenize: NLTK word_tokenize, WordPunctTokenizer,TreebankWordTokenizer(Standard) Keras text_to_word_sequence</br>
2) sentence tokenize: NLTK sent_tokenize</br>
3) Part-of-speech tagging: NLTK pos_tag</br>
4) Morpheme tokenize (For Korean): Konlpy Okt, Mecab, Komoran, Hannanum, Kkma</br>
 
